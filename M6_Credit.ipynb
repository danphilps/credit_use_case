{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5cc8190",
      "metadata": {
        "id": "a5cc8190"
      },
      "source": [
        "# Module 6: CFA\n",
        "# Use Case: Credit Risk - Identifying Bad Credit Risks\n",
        "# ===========================================\n",
        "\n",
        "In this example, we aim to predict bad consumer credits, and we develop a classification model for this purpose, driven by loan and debtor attributes. We would use this model to accept or reject a customer’s business.\n",
        "\n",
        "Dataset: Credit risk https://datahub.io/machine-learning/credit-g\n",
        "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "35f08271",
      "metadata": {
        "id": "35f08271"
      },
      "outputs": [],
      "source": [
        "# package for working with tabular data\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "# Package for charting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns #charts\n",
        "\n",
        "# package for timing runtime\n",
        "import time\n",
        "\n",
        "# package for navigating the operating system\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0xu8WyTTVNGd",
      "metadata": {
        "id": "0xu8WyTTVNGd"
      },
      "source": [
        "# Utilities: Governance and Fairness Functions\n",
        "\n",
        "First we will declare the functions we will be using to implement the Governance Framework, and principles of Fairness in our process. Install an XAI package, shap ( as appropriate), and give a high level description of the Governance framework we will use in this use-case."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo with utilities\n",
        "!git clone https://github.com/danphilps/FinGov\n",
        "os.chdir('FinGov')\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uunH93sCCS1W",
        "outputId": "efc8bc46-aaa7-4da8-ea30-30f753c6f3be"
      },
      "id": "uunH93sCCS1W",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FinGov'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 107 (delta 58), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 52.55 KiB | 912.00 KiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FairnessUtils.py',\n",
              " 'README.md',\n",
              " 'GovernanceUtils.py',\n",
              " 'data',\n",
              " '.git',\n",
              " 'StakeholderKPIReporting.py']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTROkX0WobxD",
        "outputId": "f28aba07-061c-46ec-a3cf-45047026ba00"
      },
      "id": "dTROkX0WobxD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[K     |████████████████████████████████| 575 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap) (1.5.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from shap) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from shap) (1.7.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap) (3.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import \n",
        "from StakeholderKPIReporting import StakeholderKPIReporting\n",
        "from GovernanceUtils import GovernanceUtils\n",
        "from FairnessUtils import FairnessUtils"
      ],
      "metadata": {
        "id": "rN7MwpurFzgF"
      },
      "id": "rN7MwpurFzgF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "JE0VW_oeVnah",
      "metadata": {
        "id": "JE0VW_oeVnah"
      },
      "source": [
        "## Governance Framework and Utility Function Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this use-case we will be implementing a simple Governance Framework, which we introduce in this section. Governance frameworks ensure models in an organisation achieve all their key stakeholder requirements satisfactorily, and in a safe, verifiable way. In this section we introduce functions we will use lter in thje use-case to control and monitor model development process to ensure our aims are achieved.\n",
        "\n",
        "Manys steps in a Governance Framework are qualitative, requiring professionals to assess, specify, approve or reject stages in model development. However, quantitative tools can be a powerful utility, allowing professionals to control and monitor a process, and reach judgements about model design, stability, and efficacy. \n",
        "\n",
        "We discuss the 5 stages of model development and the utility functions that can be used to support the Governance Framework:\n",
        "\n",
        "#### Stage1: Business Analysis\n",
        "We first define our stakeholder KPIs, which should be systematically defined. We introduce example functions that go some way to representing stakeholder KPIs, with visualizations, statistical tests and checks where appropriate. \n",
        "\n",
        "#### Stage2: Data Process\n",
        "Exploratory data analysis goes some way to examining the quality and nature of the data, looking at distributions, correlations, imbalances in the data. We use some utility functions to support this.\n",
        "\n",
        "#### Stage3: Model Design and Development\n",
        "From a governance point of view, model design and development is more qualitative, and requires good practice, statitically and in terms of the code implementation. Good commenting is essential, sanity checking of input and return values is advised, and in Python clear parameter declaration and control of source code, and code versions is essential too. \n",
        "We also need to ensure that the outcomes of our model are fair to different population groups, as well as having a good precision to protect the business from loan losses. We will introduce functions to ensure fairness.\n",
        "\n",
        "#### Stage4: Model Deployment\n",
        "Model deployment involes multiple stages of testing and authorization. We propose a challenger model to conduct part of this process, which is also used in the monitoring and reporting stage also.\n",
        "\n",
        "#### Stage5: Monitoring/Reporting\n",
        "During live running of the models, monitoring of data drift is essential, and for additional safety a challenger model can be run in parallel to the live model, to ensure the live model is functioning well with respect to stakeholder KPIs.\n"
      ],
      "metadata": {
        "id": "RIt23aPAHvgf"
      },
      "id": "RIt23aPAHvgf"
    },
    {
      "cell_type": "markdown",
      "id": "rDXnNSIt5GUs",
      "metadata": {
        "id": "rDXnNSIt5GUs"
      },
      "source": [
        "# Stage1. Business Case \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage one of model development is the development of the business case; why we need a model, the application, who would use it and how, and what the relative costs and banafits are for it.\n",
        "\n",
        "Since any machine learning model accuracy is never 100%, the model might err and deny credit to a qualified application.  A fair model would not disparately err in favor of one population groups versus the others. Whilt is most ofte increasing the model accuracy seems to be the most pertinent metric for model design, it is most often seen that such model might not result in fair responses t certain population groups.  \n",
        "\n",
        "In case of a credit approval process, false negatives are detrimental from the perspective of the applicant, as this will deny approval to a qualified applicant.  Recall is a measure that can be used to ensure that the false negatives are consistent across various groups.  Alternatively, from the lending institution perspective, false positives are detrimental.  This means that model precision should be maximized, which would indicate minimal false positives.\n",
        "\n",
        "The process to identify an appropriate model in this context would be to review recall values that are within acceptable limits for different population groups, concurrently maximizing the overall model precision. \n",
        "\n",
        "### Stakeholder KPIs\n",
        "#### Stakeholder KPIs: Customer\n",
        "We assume for this case study that the customer KPI is whether they achieve they achieve a positive credit decision, and whether this is fair (see below). It is also important to explain to customers why they did not achieve a positive credit decision too. This can be captured by examining the FP rate, using accuracy. We can address this using our Fairness functions, further below, and we can wrap up a check on accuracy in the function kpi_review_customer_business_compliance\n",
        "\n",
        "#### Stakeholder: The Lending Business\n",
        "From a business point of view precision is the focus, where we want to avoid false negatives, ie lend to individuals that the default. This risk has to be weighed against the need to write loans of course. We can wrap this up in the function kpi_review_customer_business_compliance\n",
        "\n",
        "#### Stakeholder KPIs: Compliance and Regulatory\n",
        "Regulatory KPIs include fairness (similar to a customer's KPI above), and also a reasonable level of precision, or risk from loan losses(simlar to the lenders KPIs). \n",
        "Fairness in this context is accuracy, the number of false negatives, of people erroneously refused credit. Ensuring accuracy is similar across different groups is essential to ensuring the model is fair to all.\n",
        "\n",
        "### Fairness\n",
        "\n",
        "For classifiers such as this model, we are looking for a probability of default threshold that is acceptable to us as the lender. If a customer has a probability of default above this threshold, we would reject the application, below and we would accept the application. By adjusting this probability of default threshold value, the false positive / false negative outputs from the model change, and need to be appropriate for the lenders capital buffer, liquidity, and risk tolerance. \n",
        "At the same time as the precision of the model is appropriate, we also need to ensure the model is fair at that level of precision (note that the false positive and false negative rates will change at different threshold values).\n",
        "One exercise to ensure fair models is to appropriately select a threshold value such that the model has similar accuracy across (ie a false negative rate) between protected and priviledged classes, and is similarly accurate for all underlying population groups. It is normally seen that there is a trade-off between accuracy and fairness when using machine learning models to make policy decisions and fairness bias should be carefully eliminated.\n",
        "\n",
        "\n",
        "The process to identify an appropriate model in this context - that is also fair to the population groups, would be to review recall values that are within acceptable limits for different population groups, concurrently maximizing the overall model precision.  Multiple models can be configured by changing the model hyper parameters.  Iterating over the various models would help identify the optimal model.The steps are as below:\n",
        "\n",
        "* Generate a set of training data, which does not include any of the protected variables such as age/gender etc. This data would be used to train the model.\n",
        "* Generate a set of test data, with the protected variable data available as columns in the dataset.  The fairness testing modules will split the test data across each of the population group based on these columns, so the model predictions can be validated for each group.\n",
        "* Identify a list of appropriate modeling techniques, that help classify the loan application to be approved/rejected \n",
        "\n",
        "The following steps help identify the appropriate model:\n",
        "* For each model, apply multiple values of the threshold at which the classification decisions are made. The threshold at which an individual outcome is classified to be approved or not can make all the difference.\n",
        "* For each of the threshold value, fit the model using a specific set of hyper parameters\n",
        "* Using the model, predict outcomes for the test data.  The model is run once for each population group. For example, if the fairness test is required for gender, the test data will be in two parts - one for male applicants and the other for female applicants.  \n",
        "* Ensure that the recall values are within acceptable limits for each of the population groups\n",
        "* Review the model precision and retain the ones with higher precision\n",
        "\n",
        "Over a set of multiple model methodologies and hyper parameters, the optimum model that maximizes precision while being fair to the population groups can be identified.\n",
        "\n",
        "\n",
        "These utility functions will be used to monitor fairness across different classes in the dataset, to ensure a similar level of accuracy in each group."
      ],
      "metadata": {
        "id": "PGuOF1tFHzyG"
      },
      "id": "PGuOF1tFHzyG"
    },
    {
      "cell_type": "markdown",
      "id": "_DfUFfsmFWh5",
      "metadata": {
        "id": "_DfUFfsmFWh5"
      },
      "source": [
        "# Stage2. Data\n",
        "\n",
        "Next we load the data we need to achieve our business aims, wrangle it and prepare it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z_M1xrqYGCJ9",
      "metadata": {
        "id": "z_M1xrqYGCJ9"
      },
      "source": [
        "## Stage2a. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LusHe3a2BF_t",
      "metadata": {
        "id": "LusHe3a2BF_t"
      },
      "outputs": [],
      "source": [
        "# Load the data from out GitHub repo...\n",
        "loc = \"data/credit-g.csv\"\n",
        "df_raw = pd.read_csv('https://raw.githubusercontent.com/danphilps/FinGov/main/data/credit-g.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cB4L-E2-Te1u",
      "metadata": {
        "id": "cB4L-E2-Te1u"
      },
      "source": [
        "There is an imbalance in the dataset, and it is possible that it could create biases in our model. **We will come back to this issue later**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tVRDgt03tG5c",
      "metadata": {
        "id": "tVRDgt03tG5c"
      },
      "source": [
        "### Check for proxies of our protected characteristics\n",
        " \n",
        "We noted that there is a bias in our dataset between the protected characterisctis of gender, with male and female credits being different, and we removed this protected characteristic from the dataset to avoid this illegal bias in loan approval outcomes.\n",
        "\n",
        "Protected characteristics can be picked up (proxied) in other dataitems in more subtle ways though. For instance given that single parent households tend to disproportionately be led by a female adult, this may make 'num_dependents' a proxy for gender.\n",
        "\n",
        "It is important that we control for any possible protected biases, and one way of achieving this is to retrain our model using a mitigator, which trains by constraining the model weights to produce a balanced outcome between protected classes; male and female credits in this case.\n",
        "\n",
        "To ascertain proxies we can check the correlation of our protected feature with ther features in the dataset.\n",
        "\n",
        "Our protected features is categorical, so compare other categorical features with our protected feature we can use a Chi2 test. \n",
        "To compare  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd49632",
      "metadata": {
        "id": "bdd49632"
      },
      "source": [
        "## Stage2b. Data Wrangling and Preprocessing\n",
        "\n",
        "Data Wrangling: As we have shown in previous chapters we need to convert categorical data into one-hot-encodings, clean characters from numeric data columns, carry out type conversions into numeric datatypes... The following cell shows the appropriate data wrangling to get our data into a good shape. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62115a2",
      "metadata": {
        "id": "c62115a2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Copt raw data into our df\n",
        "df = df_raw.copy(deep=True)\n",
        "\n",
        "# list categorical columns...\n",
        "cat_cols =['checking_status', 'purpose', 'credit_history', 'savings_status', 'employment', 'other_parties', 'property_magnitude', 'other_payment_plans','housing','job','own_telephone']\n",
        "\n",
        "# One hot encoding of catagorical variables...\n",
        "df[cat_cols].astype(\"category\")\n",
        "one_hot_encodings = pd.get_dummies(df[cat_cols])\n",
        "\n",
        "#Combine dfs\n",
        "df = pd.concat([df, one_hot_encodings], axis=1)\n",
        "\n",
        "#remove categorical columns...\n",
        "df = df.drop(columns=cat_cols)\n",
        "\n",
        "#Data wrangling..... get types and bad values sorted out\n",
        "\n",
        "# Remove characters in numeric columns (note that the data type was set, by the open_csv function to object, \n",
        "# so we first convert to string before running the replace function (which can only be fun on str types)\n",
        "df['foreign_worker'] = df['foreign_worker'].str.replace('yes', '1')\n",
        "df['foreign_worker'] = df['foreign_worker'].str.replace('no', '0')\n",
        "df['class'] = df['class'].str.replace('good', '0')\n",
        "df['class'] = df['class'].str.replace('bad', '1')\n",
        "\n",
        "# Convert to numerics so we can use in ML... we force type conversions, then print our resulting df.\n",
        "df['foreign_worker'] = pd.to_numeric(df['foreign_worker'], errors ='coerce').fillna(0).astype('int')\n",
        "df['class'] = pd.to_numeric(df['class'], errors ='coerce').fillna(0).astype('int')\n",
        "df['duration'] = pd.to_numeric(df['duration'], errors ='coerce').fillna(0).astype('int')\n",
        "df['installment_commitment'] = pd.to_numeric(df['installment_commitment'], errors ='coerce').fillna(0).astype('int')\n",
        "df['residence_since'] = pd.to_numeric(df['residence_since'], errors ='coerce').fillna(0).astype('int')\n",
        "df['age'] = pd.to_numeric(df['age'], errors ='coerce').fillna(0).astype('int')\n",
        "df['num_dependents'] = pd.to_numeric(df['num_dependents'], errors ='coerce').fillna(0).astype('int')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BrwhvERWDe_N",
      "metadata": {
        "id": "BrwhvERWDe_N"
      },
      "source": [
        "## Stage2c. Exploratory Data Analysis\n",
        "\n",
        "Once we have loaded the data and have it in a useable form, we now need to examine it, to build an intuition for the distributions, accuracy, missing values, imbalances and so on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OKIZQIrJRJOF",
      "metadata": {
        "id": "OKIZQIrJRJOF"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "\n",
        "def correlation_between_features(df: pd.DataFrame):\n",
        "    '''\n",
        "    Args:\n",
        "        df: Dataframe of the features\n",
        "       \n",
        "    Returns:\n",
        "       None\n",
        "    '''\n",
        "\n",
        "    # Descriptive stats\n",
        "    display(df.describe())\n",
        "\n",
        "    # Correlation matrix\n",
        "    plt.figure(figsize=(7,7))\n",
        "    correlation_matrix = df.corr().abs()\n",
        "    sns.heatmap(correlation_matrix, annot=True)\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "# Run simple EDA function...\n",
        "correlation_between_features(df=df)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd02130",
      "metadata": {
        "id": "1fd02130"
      },
      "source": [
        "One major bias, particularly when we are fitting a model to a relatively low probability event, such as a default, are imbalances in the data. By definition our target occurs less than half the time.\n",
        "\n",
        "#### Bias Alert: Imbalanced dataset\n",
        "\n",
        "Imbalances in datasets for classification problems are a big issue. We generally need to balance the dataset to contain an equal proportion of the different classes before training (and testing). For the credit use-case, we have two classes {1,0}, meaning that ideally 50% of our samples should be class=1; and 50% class=0. If this is not the case and we have an imbalance (we do), we can balance the data by up-sampling the minority class, or down-sampling the majority class.\n",
        "Let us first examine the dataset to determine whether it is in balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d772e1c",
      "metadata": {
        "id": "9d772e1c"
      },
      "outputs": [],
      "source": [
        "# Imbalanced y classes?\n",
        "GovernanceUtils.imbalanced_y_check(df['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0459bd5",
      "metadata": {
        "id": "e0459bd5"
      },
      "source": [
        "The dataset is not balanced. 70% of samples are class=0; only 30% are class=1. We should bring this into balance before we train our model, or risk introducing dangerous biases into our forecasts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qV1jmvnXDdEl",
      "metadata": {
        "id": "qV1jmvnXDdEl"
      },
      "source": [
        "#### Bias Alert: Protected and Majority Groups...\n",
        "\n",
        "Loan approval is a high risk application. We need to go very carefully as a result. We need to identify any protected characteristics (ie it would be illegal to differentiate based on these) present in the dataset. \n",
        "Our use-case is a loan approval use case, ethnicity and gender are protected charcteristics where biases would be illegal. We clearly need to remove these features.\n",
        "It is also possible to identify majority groups and monitor and control for  biases in our model based on these characterictics. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NQaeBvyxMddk",
      "metadata": {
        "id": "NQaeBvyxMddk"
      },
      "outputs": [],
      "source": [
        "# Check for biases on protected characteristics...\n",
        "df_female = df_raw[(df_raw['personal_status'].str.contains('female') != 0)]\n",
        "df_male = df_raw[(df_raw['personal_status'].str.contains('female') == 0)]\n",
        "\n",
        "# % of females \n",
        "female_good_credits = df_female[(df_female['class'] == 'good')].shape[0]\n",
        "female_good_credits_pct = female_good_credits / df_female.shape[0]\n",
        "#\n",
        "male_good_credits = df_male[(df_male['class'] == 'good')].shape[0] \n",
        "male_good_credits_pct = male_good_credits / df_male.shape[0]\n",
        "\n",
        "#  Difference in good credits for females and males...\n",
        "print('Female good credits: ' + str(format(round(female_good_credits_pct*100, 2))) + '%')\n",
        "print('Male good credits: ' + str(format(round(male_good_credits_pct*100, 2))) + '%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35GhK1unDr81",
      "metadata": {
        "id": "35GhK1unDr81"
      },
      "source": [
        "Having found some protected characteristics and potential biases, we need to refine the dataset to consider these. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0n2YS32BDd6N",
      "metadata": {
        "id": "0n2YS32BDd6N"
      },
      "outputs": [],
      "source": [
        "# Protected characteristics - 'personal_status' has a \"gender\" classifier - We need to remove this from model training.\n",
        "df['gender'] = np.where(df['personal_status'].str.contains('female') == 0, 1, 0) #'male'=0; female=1\n",
        "df = df.drop('personal_status', axis=1)\n",
        "\n",
        "# Another protected characteristic is age. We can categorise the ages in our dataset... \n",
        "df['age'] = df['age'].apply(lambda x: 3 if x > 65 else (2 if x > 25 else 1))\n",
        "\n",
        "# **********************************************************\n",
        "# We need to remove these columns from model training, or risk \n",
        "# illegal biases in our outcomes... \n",
        "# Keep a record of the protected columns\n",
        "protected_cols = ['gender', 'age']\n",
        "# **********************************************************"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i9Vx9c_4sStE",
      "metadata": {
        "id": "i9Vx9c_4sStE"
      },
      "source": [
        "# Stage3: Model Design \n",
        "\n",
        "Now we need to take what we have learned about the data, and find an appropriate model to achieve our KPIs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0ubSKhBH-pg",
      "metadata": {
        "id": "c0ubSKhBH-pg"
      },
      "source": [
        "## Stage 3a: Test the performance of different up, and down sampling approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e286323c",
      "metadata": {
        "id": "e286323c"
      },
      "source": [
        "Before we start up or down-sampling to correct the imbalance, we first we need to create our testing and training datasets. We can then balance the training set. This is to keep the training-set in-sample and the testing-set strictly out-of-sample. There is a risk of data leakage in this process we must consider and contriol for.\n",
        "\n",
        "#### Bias Alert: Data Leakage \n",
        "\n",
        "Separate training and testing datasets BEFORE balancing the dataset is crucial to avoid adta leakage. This is crucial as our learner must not see any of the test samples until we actually test it for performance. If we fail to separate testing and training data before up samplng, we can suffer data-snooping biases (also called data-leakage), which would invalidate our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eTjDqiD5f_j1",
      "metadata": {
        "id": "eTjDqiD5f_j1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9517124",
      "metadata": {
        "id": "f9517124"
      },
      "outputs": [],
      "source": [
        "# Define X and y variables\n",
        "cols  = list(df.columns)\n",
        "cols.remove('class')\n",
        "\n",
        "# Contains only numerics\n",
        "X = df[cols]\n",
        "y = df['class']\n",
        "\n",
        "#Test and train set    \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
        "\n",
        "#****************************\n",
        "# Keep record of protected for bias testing later\n",
        "X_train_protected = X_train[protected_cols]\n",
        "X_test_protected = X_test[protected_cols]\n",
        "\n",
        "# Remember to remove protected columns before training\n",
        "X_train = X_train.drop(protected_cols, axis=1)\n",
        "X_test = X_test.drop(protected_cols, axis=1)\n",
        "#****************************"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f79ba0",
      "metadata": {
        "id": "d3f79ba0"
      },
      "source": [
        "### Stage Test up and down sampling approaches using a Random Forest Classifier\n",
        "We will use the RandomForest classifier to help us test different up and down sampling approaches to deal with the imbalanced dataset. We will be able to see the relative performance of each balancing approach on our problem.\n",
        "\n",
        "First let us run the classifier on the imbalanced data and examine the F1 score that results when we test the model. (It is a very poor result)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02db5bb",
      "metadata": {
        "id": "c02db5bb"
      },
      "source": [
        "Get the sklearn packages we will need for our clasification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af12e96b",
      "metadata": {
        "id": "af12e96b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# metrics...\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7484849",
      "metadata": {
        "id": "c7484849"
      },
      "source": [
        "We can wrap training for the Random Forest classifier, and the printing of performance metrics in a function, as we will be running this more than once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c09b7144",
      "metadata": {
        "id": "c09b7144"
      },
      "outputs": [],
      "source": [
        "# Declare a function to wrap training of a classifier and printing of performance data\n",
        "def run_rf_classification_models(X_train: pd.DataFrame, \n",
        "                              X_test: pd.DataFrame, \n",
        "                              y_train: pd.DataFrame, \n",
        "                              y_test: pd.DataFrame) -> object:\n",
        "    \n",
        "    '''\n",
        "    Args:\n",
        "      X_train: DataFrame with training data for classifier, columns are features, rows are instances\n",
        "      X_test: Test data matching above shape\n",
        "      y_train: training data target variable {1,0}, instances are rows.\n",
        "      y_test: test data target variable {1,0}, instances are rows.\n",
        "       \n",
        "    Returns:\n",
        "       rf: sklearn model object\n",
        "       \n",
        "    Author:\n",
        "       Dan Philps\n",
        "    '''\n",
        "\n",
        "    #sanity\n",
        "    if X_train.shape[0] != y_train.shape[0]:\n",
        "      raise TypeError('Bad parameter: X_train.shape[0] != y_train.shape[0]')\n",
        "    if X_test.shape[0] != y_test.shape[0]:\n",
        "      raise TypeError('Bad parameter: X_train.shape[0] != y_train.shape[0]')\n",
        "    if (X_train.dtypes != X_test.dtypes).sum() != 0:\n",
        "      raise TypeError('Bad parameter: X_train.dtype != X_test.dtype')\n",
        "    if (y_train.dtypes != y_test.dtypes):\n",
        "      raise TypeError('Bad parameter: y_train.dtype != y_test.dtype')\n",
        "\n",
        "    # Scale and transform the data for training\n",
        "    sclr = StandardScaler()\n",
        "    sclr.fit(X_train) # scale to 0 mean and std dev 1 on training data\n",
        "\n",
        "    X_train = sclr.fit_transform(X_train) # scale both sets:\n",
        "    X_test = sclr.fit_transform(X_test)\n",
        "\n",
        "    # classifier train\n",
        "    rf = RandomForestClassifier(max_depth=5,random_state=0)\n",
        "    rf.fit(X_train,y_train)\n",
        "    y_train_hat =rf.predict(X_train)\n",
        "    y_test_hat = rf.predict(X_test)\n",
        "\n",
        "    # Analytics calculated wrt default or y=1... Print score\n",
        "    print(type(rf))        \n",
        "    print(f\"Accuracy train: {rf.score(X_train,y_train):.4f}, test: \",\n",
        "      f\"{rf.score(X_test,y_test):.4f}\")\n",
        "    print(f\"Precision train: {precision_score(y_train, y_train_hat, average=None)[1]:.4f}, test: \",\n",
        "      f\"{precision_score(y_test,y_test_hat, average=None)[1]:.4f}\")\n",
        "    print(f\"Recall train: {recall_score(y_train, y_train_hat, average=None)[1]:.4f}, test: \",\n",
        "      f\"{recall_score(y_test,y_test_hat, average=None)[1]:.4f}\")\n",
        "    print(f\"F1 train: {f1_score(y_train, y_train_hat, average=None)[1]:.4f}, test: \",\n",
        "      f\"{f1_score(y_test,y_test_hat, average=None)[1]:.4f}\")\n",
        "    \n",
        "    #Print confusion matrix...\n",
        "    cf_matrix = confusion_matrix(y_test, y_test_hat, labels=[0, 1]) \n",
        "    cf_matrix_norm = cf_matrix.astype('float') # / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    ax = sns.heatmap(cf_matrix_norm, annot=True, cmap='Blues', fmt='g')\n",
        "    ax.set_title('Confusion Matrix\\n\\n');\n",
        "    ax.set_xlabel('\\nPredicted Values')\n",
        "    ax.set_ylabel('Actual Values ');\n",
        "    plt.show()\n",
        "\n",
        "    #sanity\n",
        "    if rf is None:\n",
        "      raise TypeError('Bad return: rf is None')\n",
        "\n",
        "    return rf\n",
        "\n",
        "#run our classifier function\n",
        "mod = run_rf_classification_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print('Now use sklearns predict_proba to generate probability values for each prediction')\n",
        "mod.predict_proba(X_test)[0:9,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8166fcf",
      "metadata": {
        "id": "f8166fcf"
      },
      "source": [
        "### 3a i) Upsampling using resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ef22f5",
      "metadata": {
        "id": "a4ef22f5"
      },
      "source": [
        "First we test up-sampling using sklearn's resample, and examine how well it does using the RandomForest classifier. Resampling can up-sample by simply randomly selecting and copying existing observations of the minority class. We can balance the classes in this way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739e0d7d",
      "metadata": {
        "id": "739e0d7d"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "#Split first to avoid data-snooping\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
        "\n",
        "# Create up-sampled data set for minority class\n",
        "# note that n_samples= the number of samples the imbalance represents.\n",
        "X_upsampled, y_upsampled = resample(X_train[y_train == 1],\n",
        "                                        y_train[y_train == 1],\n",
        "                                        replace=True,\n",
        "                                        n_samples=(X_train[y_train == 0].shape[0]-X_train[y_train == 1].shape[0]),\n",
        "                                        random_state=None)\n",
        "\n",
        "#****************************\n",
        "# Keep record of protected for bias testing later\n",
        "X_upsampled_protected = X_upsampled[protected_cols]\n",
        "X_train_protected = X_train[protected_cols]\n",
        "X_test_protected = X_test[protected_cols]\n",
        "\n",
        "# Remember to remove protected columns before training\n",
        "X_upsampled = X_upsampled.drop(protected_cols, axis=1)\n",
        "X_train = X_train.drop(protected_cols, axis=1)\n",
        "X_test = X_test.drop(protected_cols, axis=1)\n",
        "#****************************\n",
        "\n",
        "#Combine train with upsampled\n",
        "X_upsampled = X_train.append(X_upsampled)\n",
        "y_upsampled = y_train.append(y_upsampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc1e5726",
      "metadata": {
        "id": "fc1e5726"
      },
      "source": [
        "Let us check everything is in balance now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8cb61d7",
      "metadata": {
        "id": "b8cb61d7"
      },
      "outputs": [],
      "source": [
        "# Imbalanced y classes?\n",
        "temp = pd.concat([X_upsampled, y_upsampled], axis=1)\n",
        "GovernanceUtils.imbalanced_y_check(temp['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53dea8e1",
      "metadata": {
        "id": "53dea8e1"
      },
      "source": [
        "Dataset is perfectly in balance..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5caebbb0",
      "metadata": {
        "id": "5caebbb0"
      },
      "outputs": [],
      "source": [
        "#Run our function....\n",
        "model = run_rf_classification_models(X_upsampled, X_test, y_upsampled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b4afcc1",
      "metadata": {
        "id": "1b4afcc1"
      },
      "source": [
        "The F1 score on the test data has increased markedly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e98b384e",
      "metadata": {
        "id": "e98b384e"
      },
      "source": [
        "### 3a ii) Up-sampling using a synthetic over sampling approach called SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235505f6",
      "metadata": {
        "id": "235505f6"
      },
      "source": [
        "Add the libraries we will need... and generate the synthetic data to balance our classes using SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dadf40d",
      "metadata": {
        "id": "5dadf40d"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#How many samples do we need to balance?\n",
        "idx = np.random.choice(X_train.shape[0], size=X_train[y_train == 0].shape[0]-X_train[y_train == 1].shape[0], replace=False)\n",
        "\n",
        "# Generate SMOTE samples and use this to train\n",
        "upsampler_smote = SMOTE()\n",
        "X_upsampled_smote, y_upsampled_smote = upsampler_smote.fit_resample(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JQKlvmapJgqT",
      "metadata": {
        "id": "JQKlvmapJgqT"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a14d264",
      "metadata": {
        "id": "4a14d264"
      },
      "source": [
        "Before we use the up-sampled dataset to train our classifier, let us first examine the distribution of the synthetic datapoints that SMOTE creates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff54d69",
      "metadata": {
        "id": "4ff54d69"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7)) \n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(X_train['credit_amount'],X_train['installment_commitment'], X_train['duration'], marker=\"o\", s=10, c='blue', label='Real datapoints')\n",
        "ax.scatter(X_upsampled_smote['credit_amount'],X_upsampled_smote['installment_commitment'], X_upsampled_smote['duration'], marker=\"+\", s=50, c='red', label='SMOTE datapoints')\n",
        "\n",
        "# set axes range\n",
        "plt.xlim(-500, 11000)\n",
        "plt.ylim(0, 40)\n",
        "\n",
        "ax.set_xlabel('credit_amount')\n",
        "ax.set_ylabel('installment_commitment')\n",
        "ax.set_zlabel('duration')\n",
        "\n",
        "plt.title= 'How SMOTE Samples are Distributed vs Real Data Points'\n",
        "plt.legend(loc=1,framealpha=1, fontsize=8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a875103b",
      "metadata": {
        "id": "a875103b"
      },
      "source": [
        "The synthetic datapoints look realistic at a glance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c031433f",
      "metadata": {
        "id": "c031433f"
      },
      "outputs": [],
      "source": [
        "# Imbalanced y classes?\n",
        "temp = pd.concat([X_upsampled_smote, y_upsampled_smote], axis=1)\n",
        "GovernanceUtils.imbalanced_y_check(temp['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d8fdc6",
      "metadata": {
        "id": "89d8fdc6"
      },
      "source": [
        "After up-sampling using SMOTE's synthetic data, the dataset is perfectly in balance... however we have a Fairness problem. Can you spot what it is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750a6983",
      "metadata": {
        "id": "750a6983"
      },
      "outputs": [],
      "source": [
        "#Run our function....\n",
        "model = run_rf_classification_models(X_upsampled_smote, X_test, y_upsampled_smote, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kHUCz-3ksp6r",
      "metadata": {
        "id": "kHUCz-3ksp6r"
      },
      "source": [
        "### 3a iii) Down-sampling - Removing rows to balance the classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a94d7e4",
      "metadata": {
        "id": "0a94d7e4"
      },
      "source": [
        "Now we can test down-sampling, which is simply removing samples from the majority class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dbc9854",
      "metadata": {
        "id": "8dbc9854"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler \n",
        "\n",
        "#Split first to avoid data-snooping\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
        "\n",
        "#****************************\n",
        "# Keep record of protected for bias testing later\n",
        "X_train_protected = X_train[protected_cols]\n",
        "X_test_protected = X_test[protected_cols]\n",
        "\n",
        "# Remember to remove protected columns before training\n",
        "X_train = X_train.drop(protected_cols, axis=1)\n",
        "X_test = X_test.drop(protected_cols, axis=1)\n",
        "#****************************\n",
        "\n",
        "# Randomly downsample rows in the majority class\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_downsampled, y_downsampled = rus.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0beacf7",
      "metadata": {
        "id": "c0beacf7"
      },
      "outputs": [],
      "source": [
        "# Imbalanced y classes?\n",
        "temp = pd.concat([X_downsampled, y_downsampled], axis=1)\n",
        "GovernanceUtils.imbalanced_y_check(temp['class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6de0276",
      "metadata": {
        "id": "d6de0276"
      },
      "outputs": [],
      "source": [
        "# Run our function to train a rf classifier....\n",
        "model = run_rf_classification_models(X_downsampled, X_test, y_downsampled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6ea491",
      "metadata": {
        "id": "5e6ea491"
      },
      "source": [
        "As we can see, all up and down sampling approaches have outperformed the F1 Score on the imbalanced data. The most impressive performance in this case is from up-sampling using SMOTE synthetic data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66bfe3c2",
      "metadata": {
        "id": "66bfe3c2"
      },
      "source": [
        "## Stage 3b: Model Selection\n",
        "\n",
        "\n",
        "Next we need to select the type of classifier we are going to use to model our problem and separate good from bad credits. We could just make a heuristic selection, but we are likely to be biased in making this selection. \n",
        "\n",
        "#### Bias Alert: Availability Heuristic\n",
        "For instance,  is our quant team overpopulated by linear regression experts? Do we have a greater level of familiarity for Random Forest classifiers?\n",
        "\n",
        "One way of dealing with this is to use of develop a model selection approach. We can test the problem, using many different classsifiers and assess the performance of exach based on our KPIs. However, we must be careful as even this more exhaustive approach is also open to biases. For instance if we are selection models based on p-values, we would suffer from multiplicity bias where testing multiple approaches would exaggerate the significance of a success. \n",
        "\n",
        "#### Bias Alert: Multiplicity bias\n",
        "\n",
        "To control for this we would use a measure such as F1-score, and we would test this on test samples not used for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tUbobdmKR9Or",
      "metadata": {
        "id": "tUbobdmKR9Or"
      },
      "outputs": [],
      "source": [
        "# Get cross-validation set, broken out from training data, to select the classifier\n",
        "# objective is to keep the classifier choice in sample, so that running on the test data \n",
        "# will be a true out-of-sample test. No data leakage bias.\n",
        "\n",
        "# Test and train set    \n",
        "X_train_cv, X_cv, y_train_cv, y_cv = train_test_split(X_train, y_train, test_size=0.3, random_state=None)\n",
        "\n",
        "# Cross validation as a subset of \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
        "\n",
        "#****************************\n",
        "# Keep record of protected for bias testing later\n",
        "X_train_protected = X_train[protected_cols]\n",
        "X_test_protected = X_test[protected_cols]\n",
        "\n",
        "# Remember to remove protected columns before training\n",
        "X_train = X_train.drop(protected_cols, axis=1)\n",
        "X_test = X_test.drop(protected_cols, axis=1)\n",
        "#****************************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JElvKh2qh75k",
      "metadata": {
        "id": "JElvKh2qh75k"
      },
      "source": [
        "Sklean provides many different classifiers and we will be testing a wide range to determine their accuracy on our problem. To address the availability heuristic we will now build a function that tests a number of different classifiers on our problem, and the one with the best accuracy on the cross-validation data, we will select as the \"best\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cyji4ydlQTVZ",
      "metadata": {
        "id": "cyji4ydlQTVZ"
      },
      "outputs": [],
      "source": [
        "# Run our function....autoselect the best classifier wrt F1\n",
        "max_mdl, all_models, all_models_desc, all_mdls_prec = GovernanceUtils.auto_classifier_selection(X_train_cv, X_cv, y_train_cv, y_cv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OHdKdhL6MF42",
      "metadata": {
        "id": "OHdKdhL6MF42"
      },
      "source": [
        "The output from our model selection function shows how each classifier performed on the training and cross-validation datasets. We can now test the \"winning classifier\" on our test data to ensure the cross-validation tests were effective in selecting a good performance out of sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BuJjXTsYMbBs",
      "metadata": {
        "id": "BuJjXTsYMbBs"
      },
      "outputs": [],
      "source": [
        "# Predict\n",
        "y_test_hat = max_mdl.predict(X_test.values)\n",
        "\n",
        "# Analyst KPI...\n",
        "f1, prec, rec = StakeholderKPIReporting.kpi_review_analyst(mdl=max_mdl,X=X_test, y=y_test[:].values, y_hat=y_test_hat[:])\n",
        "print(f1, prec, rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RM6iBjWd_yEn",
      "metadata": {
        "id": "RM6iBjWd_yEn"
      },
      "source": [
        "#### Bias Alert: Inductive bias\n",
        "\n",
        "Even in the case where we select the most appropriate model, we may still be exposed to inductive biases. Each learner has a specific way that will approximate the function we are attempting to approximate, in this cadse the function of credit quality based on the characteristics of borrowers. Decision Trees, for instance, have inductive biases associated with greedy separation, whereas Random Forests (RF) mitigate this bias by using many randomized decision trees, but in turn introduce (lesser) inductive biases associated with the way an RF's underlying decision trees are contructed. One mitigant is to ensemble different learners, using a soft-max function or a voting approach. For voting based ensembling we would simply run a number of classifiers, take the majority answer: good/bad credit. (Note that we have included \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xjkMTtAW22C6",
      "metadata": {
        "id": "xjkMTtAW22C6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Run the challenger ensemble\n",
        "y_test_hat, ens_mdl = GovernanceUtils.challenger_ensemble_run(all_mdls=all_models,\n",
        "                        all_mdls_desc=all_models_desc,\n",
        "                        all_mdls_prec=all_mdls_prec,\n",
        "                        X_train=X_train,\n",
        "                        y_train=y_train,\n",
        "                        X_test=X_test)\n",
        "\n",
        "# Analyst KPI...\n",
        "f1, prec, rec = StakeholderKPIReporting.kpi_review_analyst(mdl=ens_mdl,X=X_test.values, y=y_test[:].values, y_hat=y_test_hat[:])\n",
        "print(f1, prec, rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LvIWjJXQtAVd",
      "metadata": {
        "id": "LvIWjJXQtAVd"
      },
      "source": [
        "## Stage 3c: Fairness\n",
        "\n",
        "We need to ensure that accuracy is similar across different population groups, in other words that there is no unfairness in model outcomes that can be linked to these groups. To do this we use the utilities we introduced earlier in the notebook. We also need to make sure the lender achieves its lending KPIs, and to balance fairness with our KPIs we will alter the threshold (relating to probability of default) of loan acceptance until we achieve a result that best achieves all stakehjolder KPIs. We will now explain this process...\n",
        "\n",
        "We need to examine recall to ensure fairness (a customer KPI) and precision (a business KPI) to ensure we have an acceptable false positive rate. For the fairness tests we will look at different population groups: gender(Male/Female) and Age Group (Below 25/25-60/Above 60 age groups. In a fair model, each of the population groups should not be more than 20% worse-off than the majority group. \n",
        "The plots display the range as between the two red lines. Any population group with a metric value outside the range between the red lines is impacted negatively by the model. Adjusting the model parameters or\n",
        "\n",
        "Higher the recall values, the lower is the False Negatives. Higher the precision values, the lower is False Positives. A judgement call is neeeded to confirm if the false positives have more adverse impact or false negatives. In case of credit approval process, for a loan applicant, false negatives should be minimized. So recall is the more appropriate measure.\n",
        "\n",
        "We will execute the following steps:\n",
        "* Review fairness of our model overall, regarding specific groups\n",
        "* We will test lending thresholds for fairness, first a conservative one (0.9), then a more aggressive one (0.5)\n",
        "* Find optimium threshold: Finally we will search for the optimium threshold, that achieves the lender KPIs best, at the same time remaining fair within our tolerances."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3c i): High level fairness checks for model"
      ],
      "metadata": {
        "id": "z-lAHp_MSPdn"
      },
      "id": "z-lAHp_MSPdn"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_protected"
      ],
      "metadata": {
        "id": "_lvxAxb6aXp1"
      },
      "id": "_lvxAxb6aXp1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3c ii): Fairness checks for specific lending thresholds"
      ],
      "metadata": {
        "id": "qm5NY2AESSH_"
      },
      "id": "qm5NY2AESSH_"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_gender = pd.Series(X_test_protected['gender'].apply(lambda x: 'male' if x==1 else 'female'))"
      ],
      "metadata": {
        "id": "E9vMqJzer9cQ"
      },
      "id": "E9vMqJzer9cQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af39a70d",
      "metadata": {
        "id": "af39a70d"
      },
      "outputs": [],
      "source": [
        "# Test a 0.5 threshold for fairness...\n",
        "df_stats = FairnessUtils.fairness_stats_get (mod=max_mdl, \n",
        "                               X_test=X_test, \n",
        "                               y_test=y_test, \n",
        "                               X_test_category_col=X_test_gender, \n",
        "                               y_approval_threshold=0.5)\n",
        "\n",
        "FairnessUtils.plot_fairness_charts(df_stats, \"male\", \"recall\", \"precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7af46f0",
      "metadata": {
        "id": "d7af46f0"
      },
      "source": [
        "In the above example, it is seen that using a threshold of 0.5, the model is not seen fair - the recall value Females is outside of the 20% rane from the recall value for Males, indicating that the decision makes females worse off compared to Males. Now let us try to run the model with a threshold of 0.9, i.e. the model outcome should have a probabiity exceeding 0.9 to accept a specific response.  In this case, it is seen that the model is fair and has a high recall, while the precision is low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd80f306",
      "metadata": {
        "id": "fd80f306"
      },
      "outputs": [],
      "source": [
        "# Test a 0.9 threshold for fairness...\n",
        "df_stats = FairnessUtils.fairness_stats_get (mod=max_mdl, \n",
        "                               X_test=X_test.copy(deep=True), \n",
        "                               y_test=y_test.copy(deep=True), \n",
        "                               X_test_category_col=pd.Series(X_test_gender).copy(deep=True), \n",
        "                               y_approval_threshold=0.9)\n",
        "\n",
        "FairnessUtils.plot_fairness_charts(df_stats, \"male\", \"recall\", \"precision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3c iii): Optimum Lender KPIs while achieving Fairness..."
      ],
      "metadata": {
        "id": "wmK8GGoISato"
      },
      "id": "wmK8GGoISato"
    },
    {
      "cell_type": "markdown",
      "id": "a8899446",
      "metadata": {
        "id": "a8899446"
      },
      "source": [
        "\n",
        "Utilize the process process defined earlier to identify an appropriate model in this context by reviewing recall values that are within acceptable limits for different population groups, concurrently maximizing the overall model precision. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d379c310",
      "metadata": {
        "id": "d379c310"
      },
      "outputs": [],
      "source": [
        "# Get the optimal threhold to use, by iterating with different values of threshold, that determines the model outcomes.\n",
        "optimal_threshold = FairnessUtils.decision_threshold_find_optimal(max_mdl, X_test, y_test, X_test_gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The threshold that maximizes business KPI, while avoiding bias in the classes monitored is ..."
      ],
      "metadata": {
        "id": "5J5M7xoa7a7_"
      },
      "id": "5J5M7xoa7a7_"
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_threshold"
      ],
      "metadata": {
        "id": "3siqlNSe68yi"
      },
      "id": "3siqlNSe68yi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0LFyHIAP59O7",
      "metadata": {
        "id": "0LFyHIAP59O7"
      },
      "source": [
        "# Stage4: Model Deployment \n",
        "\n",
        "Model deployment generally involves a change process, several levels of testing and sign off, asignment of responsibilities for the live operation of the process, models and data before deployiong the code to the cloud (or on native hardware). \n",
        "A key part of thius stage is communication of the KPIs to stakleholders to enable them to understand the way the models operate, the risks involved and to be accountable for deploying the models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xDmGSQUV2Fle",
      "metadata": {
        "id": "xDmGSQUV2Fle"
      },
      "source": [
        "## Stage4a. KPIs\n",
        "\n",
        "We have already tested our models for the most important KPIs ... check. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JZGI4nBO0HlI",
      "metadata": {
        "id": "JZGI4nBO0HlI"
      },
      "source": [
        "## Stage4b. Communication: Stakeholder Oriented Explanations\n",
        "\n",
        "Communication of how the model has reached the outcomes it is has, is crutial to achieve fairness, transparency, accountability, and trust in the whole process. Each stakeholder in the process needs to see different elements. The Data Scientist and technical leadership need to review the nut and bolts of the model, reviewing residuals plots, parameter importance, interaction terms and many other metrics. The customer needs to see far less information, and mainly that associated with a refusal of credit. Compliance resources and regulators need to see something different again, such as fairness regarding protected characteristics, the accuracy and therefore capital risk represented by the models. \n",
        "In this section we look at stakeholder oriented explanations and we will be using standard charts of important analytics, such as residual plots, and SHAP.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "p_R8AuM3syKh"
      },
      "id": "p_R8AuM3syKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "Ku_I-kcG8bpR",
      "metadata": {
        "id": "Ku_I-kcG8bpR"
      },
      "source": [
        "Now instantiate the SHAP explainer object for our classifier and generate Shapley values for the test data... Note that as we will be using the test data, all the analysis is therefore based on the out of sample performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_mdl = all_models[1]"
      ],
      "metadata": {
        "id": "PtaWA1cH55SI"
      },
      "id": "PtaWA1cH55SI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_xCoD7kw6r0b",
      "metadata": {
        "id": "_xCoD7kw6r0b"
      },
      "outputs": [],
      "source": [
        "shap_values, expl, X_test_reduced, X_test_protected_reduced = StakeholderKPIReporting.classifier_shap_vals(max_mdl=max_mdl, \n",
        "                                                                                                           X_test=X_test,                                                                                      \n",
        "                                                                                                           X_test_protected=X_test_protected)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdMhCBHMFf4v",
      "metadata": {
        "id": "bdMhCBHMFf4v"
      },
      "source": [
        "### 1) Analyst and technical explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fPlSWba2dSoo",
      "metadata": {
        "id": "fPlSWba2dSoo"
      },
      "outputs": [],
      "source": [
        "# Analyst KPI...\n",
        "StakeholderKPIReporting.kpi_review_analyst(mdl=max_mdl,X=X_test, y=y_test, y_hat=y_test_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8u7btmtyFKNn",
      "metadata": {
        "id": "8u7btmtyFKNn"
      },
      "source": [
        "Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NfwlscWzExPQ",
      "metadata": {
        "id": "NfwlscWzExPQ"
      },
      "outputs": [],
      "source": [
        "# Plot the feature importance\n",
        "#shap.plots.bar(shap_values=shap_values, max_display=30, show=False)\n",
        "shap.summary_plot(shap_values, X_test_reduced, feature_names=list(X_test_reduced.columns.values), plot_type='bar', show=False)\n",
        "plt.title = \"Feature Importance: Credit-Use Case Feature Importance\"\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0S8f3dp_xkqS",
      "metadata": {
        "id": "0S8f3dp_xkqS"
      },
      "source": [
        "Beeswarm plot, showing features ranking by importance, and the impact of each instance passed to the shap explainer. Note the feature value is color coded from \"high\" to \"low\" (vertical axis), and the Shap value represents the impact on the model output of the value (horixontal axis). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r0GjSB9YxlEl",
      "metadata": {
        "id": "r0GjSB9YxlEl"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_test_reduced, show=False)\n",
        "plt.title = \"Beeswarm: Credit-Use Case Feature Importance and Dependency\"\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1fcWInh48Q",
      "metadata": {
        "id": "ce1fcWInh48Q"
      },
      "source": [
        "### 2) Compliance and Regulatory\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fxV86fMFKX7r",
      "metadata": {
        "id": "fxV86fMFKX7r"
      },
      "source": [
        "Qualitatively check to see if any features are suspiciously important for one (eg) gender vs another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nqJGtpmu1nig",
      "metadata": {
        "id": "nqJGtpmu1nig"
      },
      "outputs": [],
      "source": [
        "# Some learners do not have direct support from shap. \n",
        "try:\n",
        "  # Feature importance by protected characteristic.. different treatment?\n",
        "  for prot_char in X_test_protected.columns:\n",
        "    # Extract the protected classes.\n",
        "    curr_prot_cats = X_test_protected_reduced[prot_char].astype(str).to_list() \n",
        "\n",
        "    # Plot the feature importance\n",
        "    shap.plots.bar(shap_values.cohorts(curr_prot_cats).abs.mean(0), show=False)\n",
        "    \n",
        "    plt.title= \"Bias Check: Feature Importance of protected group: \" + prot_char\n",
        "    plt.show()\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Threshold to determine loan acceptances, and fairness of those acceptances for our model..."
      ],
      "metadata": {
        "id": "8WwRH7DmSr51"
      },
      "id": "8WwRH7DmSr51"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our optimum threshold\n",
        "df_stats = FairnessUtils.fairness_stats_get(max_mdl, X_test, y_test, X_test_gender, optimal_threshold)\n",
        "\n",
        "FairnessUtils.plot_fairness_charts(df_stats, \"male\", \"recall\", \"precision\")"
      ],
      "metadata": {
        "id": "1huFH12USsKh"
      },
      "id": "1huFH12USsKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "De8c3JUdKvtR",
      "metadata": {
        "id": "De8c3JUdKvtR"
      },
      "source": [
        "### 3) Customer\n",
        "\n",
        "A customer may want to knowlt he sensitivity of the decision to certain characteristics. IF a refusal has been made, it would be beneficial to report to the customer what they need to change to get a favorable outcome. \n",
        "\n",
        "We can use the SHAP waterfall plot to help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ZHyTdYTLCh8",
      "metadata": {
        "id": "4ZHyTdYTLCh8"
      },
      "outputs": [],
      "source": [
        "# Find a customer with bad credit prediction\n",
        "for rejected_eg_rowno in range(0,y_test.shape[0]):\n",
        "  if y_test.iloc[rejected_eg_rowno] == 1:\n",
        "    break\n",
        "\n",
        "# This customer was refused credit and we can provide an explanation for their refusal...\n",
        "try:\n",
        "  shap.plots.waterfall(shap_values[rejected_eg_rowno])\n",
        "except:\n",
        "  print('Shap charts of this type are not supported for this model type.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TTN8r_7zRDbt",
      "metadata": {
        "id": "TTN8r_7zRDbt"
      },
      "source": [
        "# Stage 5: Model Monitoring and Reporting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Our model is now in production and being used in practice. We are \"risk on\" and we need to continually monitor and record our KPIs. Individuals accountability for these processes is critical.\n",
        "\n",
        "We also need to monitor data drift. If the distribution or the nature of the data we pass into our model substantioally differs from our training data, our model results will almost certainly be garbage. We need to monitor data drift and should drift occurr we need to re-run our model developmnent process to traing an appropriate model. This would take us back to Stage2 in this process.\n",
        "\n",
        "There is also the question of whether our model is still the best approach as time steps forward? Our model paramaters may become stale, the model itself may be less appropriaytr given its inductive biases. Many things can change and to monitor this we should consider using a challenger model. Challenger models are used to compete against our live model, and we should monitor our KPIs generated by our live model and compare them to those produced by the challenger model. "
      ],
      "metadata": {
        "id": "bnPGVy87H5Y9"
      },
      "id": "bnPGVy87H5Y9"
    },
    {
      "cell_type": "markdown",
      "id": "j3se-Ud-Spu3",
      "metadata": {
        "id": "j3se-Ud-Spu3"
      },
      "source": [
        "## Stage5a: Data Drift\n",
        "\n",
        "As a test of how to perform an analysis of data drift let us compare the build data distribution of feature or target values vs. the test data distribtuion of feature or target values. However, once in production you would comapare the distribution at periodic times, typically monthly, to a baseline value, or to prior month to pick up any trends in the featur or target distribution shifting.\n",
        "\n",
        "To demonstrate how this is done we can test PSI, for the training target and the test target, y_train, y_test. \n",
        "If this results in a greater than 0.20 difference than we should investigate the features, or variables, using a\n",
        "similar test to see which features are responsible for the drift in the target, by looking at X_train vs. X_test.\n",
        "\n",
        "However, even if the target variable PSi is not breaching, it is always good to keep track of the features to see if\n",
        "there is a change in the distribution, which may require a recalibration of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QREnQ1poSmRR",
      "metadata": {
        "id": "QREnQ1poSmRR"
      },
      "outputs": [],
      "source": [
        "# PRepare train and test data for data drift check\n",
        "train_datadrift = pd.concat([X_train, y_train], axis=1)\n",
        "test_datadrift = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Data drift check...\n",
        "data_drift_features = GovernanceUtils.data_drift_psi(train_datadrift,test_datadrift,buckettype='bins',buckets=10,axis=1,single_variable=False)\n",
        "data_drift_target = data_drift_features[-1]\n",
        "\n",
        "# Print out the target PSI value:\n",
        "print(\"Target PSI value is \",data_drift_target, \"\\n\" )\n",
        "\n",
        "# Print out the features CSI values\n",
        "print(\"The feature CSI values are:\")\n",
        "columns_features = train_datadrift.columns\n",
        "index_value = 0\n",
        "for x in columns_features:\n",
        "  if data_drift_features[index_value] > 0.2:\n",
        "          print(x, \"*************** CSI value is over 0.2 = \",data_drift_features[index_value])\n",
        "  elif data_drift_features[index_value] > 0.1:\n",
        "          print(x, \"*************** CSI value is over 0.1 = \",data_drift_features[index_value])\n",
        "  else:\n",
        "          print(x, \"CSI is OK = \",data_drift_features[index_value])\n",
        "  index_value = index_value + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_drift_features"
      ],
      "metadata": {
        "id": "XS0cx7JinKKw"
      },
      "id": "XS0cx7JinKKw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4wmYyfyWRmrR",
      "metadata": {
        "id": "4wmYyfyWRmrR"
      },
      "source": [
        "## Stage5b: Challenger Models\n",
        "\n",
        "So what model do we use as a challenger, and when do we traing it? There are no perfect answers but we can use our model development pipeline to help. Note that our model selection function, auto_classifier_selection, allowed us to generate a range of classifiers, we can use one or all of these classifiers as our challenger. If we decided to ensemble the classifiers as our live model (ir combine the results of all in a voting ensemble for instance) we can select the best single model as our challeger. If we decided to use the best single model as our live model, we can use a boting ensemble as our challenger.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_8v9zlaWTd3F",
      "metadata": {
        "id": "_8v9zlaWTd3F"
      },
      "outputs": [],
      "source": [
        "# Run the challenger ensemble\n",
        "y_test_hat, ens_mdl = GovernanceUtils.challenger_ensemble_run(all_mdls=all_models,\n",
        "                        all_mdls_desc=all_models_desc,\n",
        "                        all_mdls_prec=all_mdls_prec,\n",
        "                        X_train=X_train,\n",
        "                        y_train=y_train,\n",
        "                        X_test=X_test)\n",
        "\n",
        "# Do we need to retrain the live model?\n",
        "challenger_check_warning = GovernanceUtils.challenger_review_live(live_mod=max_mdl, challenger_mod=ens_mdl, X_test=X_test, y_test=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not we see if there are any warnings to do with the performance of our live model versus the Challenger model: \n",
        "# ... '' means ... no warnings\n",
        "challenger_check_warning"
      ],
      "metadata": {
        "id": "2G7xB1Tk-Le4"
      },
      "id": "2G7xB1Tk-Le4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Afterword\n",
        "\n",
        "We have done our best to include the key themes of what we think are the critical stages of model development in this notebook, but clearly in practice many more checks and details would be added to each of the 5 model development stages to best ensure stakeholders KPIs are met, and Governance standards would be as high as possible. Hopefully our example and key themes will provide insight to avioid many of the classic biases in model development."
      ],
      "metadata": {
        "id": "maH6e9W3S-Va"
      },
      "id": "maH6e9W3S-Va"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}